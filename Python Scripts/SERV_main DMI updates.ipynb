{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORTS 2024\n",
      "------------------------------------------\n",
      "All good. Detected with 2121 rows\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2023-12-29'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P185, DMI_Mothly_Report\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tabulate import tabulate\n",
    "user = os.getlogin()\n",
    "basefolder = 'C:/Users/'+user+'/A&D Mortgage(1)/Docs - Servicing/DMI/REPORTS/'\n",
    "cwdteams = os.path.abspath(basefolder) \n",
    "root_folder = os.listdir(cwdteams)\n",
    "\n",
    "columnsCheck = ['InvestorCode',\n",
    " 'OfficeCode',\n",
    " 'LoanNumber',\n",
    " 'BorrowerShortName',\n",
    " 'BorrowerInitials',\n",
    " 'CategoryCode',\n",
    " 'InvestorLoanNumber',\n",
    " 'LoanTypeCode',\n",
    " 'DistributionType',\n",
    " 'PrincipalBalancePresent',\n",
    " 'PIConstant',\n",
    " 'InterestRate',\n",
    " 'OriginalTermMonthCount',\n",
    " 'PaymentNumber',\n",
    " 'PaymentFrequencyCode',\n",
    " 'DueDateEffective',\n",
    " 'ID',\n",
    " 'AccruedInterestReceivableAmount',\n",
    " 'InterestEarnedInAdvance',\n",
    " 'InterestRateCalculationMessageAccrual',\n",
    " 'PICalculationMessageAccrual',\n",
    " 'CalculationInterestRateAccrual',\n",
    " 'CalculationPIAccrual',\n",
    " 'StatusCodeAccrual',\n",
    " 'StatusNameAccrual',\n",
    " 'StatusDayCountAccrual',\n",
    " 'DateAccrualThruAccrual',\n",
    " 'ReceivedAmountAccrual',\n",
    " 'ReceivedAmountDifferenceAccrual',\n",
    " 'AsOfDate'\n",
    "]\n",
    "\n",
    "mistakes_dupl_csv = []\n",
    "mistakes_columns = []\n",
    "missed_file = []\n",
    "files_written = []\n",
    "file_total = 0\n",
    "counter = 0\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year_folder in root_folder:\n",
    "    if 'REPORTS 2024' in year_folder:\n",
    "        print (year_folder)\n",
    "        year_destination = os.listdir(basefolder + year_folder)   \n",
    "        for month_folder in year_destination:\n",
    "            if '.' not in month_folder and '01-2024' in month_folder:\n",
    "                #print (month_folder)\n",
    "                month_destination = os.listdir(basefolder + year_folder + '/' + month_folder)\n",
    "                counter = 0\n",
    "                for files in month_destination:\n",
    "                    if 'P185' in files and '.csv' in files and '_D--' in files:\n",
    "                        #print(month_folder + '\\n' + files)\n",
    "                        csvpath = basefolder + year_folder + '/'+ month_folder + '/' + files\n",
    "                        counter= counter+1\n",
    "                        file_total = file_total+1\n",
    "                        if counter < 2:\n",
    "                            data = pd.read_csv(csvpath)\n",
    "                            data[\"AsOfDate\"] = files[14:24]\n",
    "                            if list(data.columns) == columnsCheck:\n",
    "                                df = pd.concat([df, data], ignore_index=True)\n",
    "                                files_written.append(files[14:24])\n",
    "                            else: \n",
    "                                mistakes_columns.append(files[14:24])\n",
    "                        else:\n",
    "                            mistakes_dupl_csv.append(csvpath)\n",
    "\n",
    "print('------------------------------------------')\n",
    "if len(files_written) == file_total:\n",
    "    print(f'All good. Detected with {len(df)} rows')\n",
    "    print('------------------------------------------')\n",
    "else:\n",
    "    if len(mistakes_dupl_csv) >0:\n",
    "        print('Duplicated csvs path: '+ mistakes_dupl_csv)\n",
    "        print('------------------------------------------')\n",
    "    if len(mistakes_columns) >0:\n",
    "        print('Duplicated csvs path: '+ mistakes_columns)\n",
    "        print('------------------------------------------')\n",
    "np.unique(df['AsOfDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import String\n",
    "\n",
    "engine = create_engine(\"mssql+pyodbc://bi_report:kqFD45BGQ30Gc3DVXFei5PAXIe3k6pq3@bi-01.prod.admortgage.com/dm01?driver=ODBC Driver 17 for SQL Server\")\n",
    "df.to_sql('SERV_DMI_Monthly_Report', con=engine, index = False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORTS 2024\n",
      "------------------------------------------\n",
      "All good. Detected with 7 rows\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2023-12-29'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S214, SERV_DMI_PaidOff_Monthly_Report\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tabulate import tabulate\n",
    "user = os.getlogin()\n",
    "basefolder = 'C:/Users/'+user+'/A&D Mortgage(1)/Docs - Servicing/DMI/REPORTS/'\n",
    "cwdteams = os.path.abspath(basefolder) \n",
    "root_folder = os.listdir(cwdteams)\n",
    "\n",
    "columnsCheck = ['LoanNumber',\n",
    " 'InvestorLoanNumber',\n",
    " 'InvestorCode',\n",
    " 'CategoryCode',\n",
    " 'PenInterest',\n",
    " 'PenServiceFee',\n",
    " 'Memo',\n",
    " 'DatePaid',\n",
    " 'PaymentNumber',\n",
    " 'Escrow',\n",
    " 'Principal',\n",
    " 'Interest',\n",
    " 'ServiceFee',\n",
    " 'NetInterest',\n",
    " 'DepositedRemitted',\n",
    " 'PrincipalBalance',\n",
    " 'LateCharge',\n",
    " 'OtherTrust',\n",
    " 'Asterisk',\n",
    " 'PIConstant',\n",
    " 'AnnualIR',\n",
    " 'SFRate',\n",
    " 'DueDate',\n",
    " 'AsOfDate']\n",
    "\n",
    "mistakes_dupl_csv = []\n",
    "mistakes_columns = []\n",
    "missed_file = []\n",
    "files_written = []\n",
    "file_total = 0\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year_folder in root_folder:\n",
    "    if 'REPORTS 2024' in year_folder:\n",
    "        print (year_folder)\n",
    "        year_destination = os.listdir(basefolder + year_folder)   \n",
    "        for month_folder in year_destination:\n",
    "            if '.' not in month_folder and '01-2024' in month_folder:\n",
    "                #print (month_folder)\n",
    "                month_destination = os.listdir(basefolder + year_folder + '/' + month_folder)\n",
    "                counter = 0\n",
    "                for files in month_destination:\n",
    "                    if 'S214' in files and '.csv' in files and '_E1--' in files:\n",
    "                        #print(month_folder + '\\n' + files)\n",
    "                        csvpath = basefolder + year_folder + '/'+ month_folder + '/' + files\n",
    "                        #print(csvpath)\n",
    "                        counter= counter+1\n",
    "                        file_total = file_total+1\n",
    "                        if counter < 2:\n",
    "                            data = pd.read_csv(csvpath)\n",
    "                            data[\"AsOfDate\"] = files[14:24]\n",
    "                            if list(data.columns) == columnsCheck:\n",
    "                                df = pd.concat([df, data], ignore_index=True)\n",
    "                                files_written.append(files[14:24])\n",
    "                            else: \n",
    "                                mistakes_columns.append(files[14:24])\n",
    "                        else:\n",
    "                            mistakes_dupl_csv.append(csvpath)\n",
    "\n",
    "print('------------------------------------------')\n",
    "if len(files_written) == file_total:\n",
    "    print(f'All good. Detected with {len(df)} rows')\n",
    "    print('------------------------------------------')\n",
    "else:\n",
    "    if len(mistakes_dupl_csv) >0:\n",
    "        print('Duplicated csvs path: '+ mistakes_dupl_csv)\n",
    "        print('------------------------------------------')\n",
    "    if len(mistakes_columns) >0:\n",
    "        print('Duplicated csvs path: '+ mistakes_columns)\n",
    "        print('------------------------------------------')\n",
    "np.unique(df['AsOfDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import String\n",
    "\n",
    "engine = create_engine(\"mssql+pyodbc://bi_report:kqFD45BGQ30Gc3DVXFei5PAXIe3k6pq3@bi-01.prod.admortgage.com/dm01?driver=ODBC Driver 17 for SQL Server\")\n",
    "df.to_sql('SERV_DMI_PaidOff_Monthly_Report', con=engine, index = False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORTS 2024\n",
      "C:/Users/NurlanKer/A&D Mortgage(1)/Docs - Servicing/DMI/REPORTS/REPORTS 2024/01-2024/P139_Data_Q05_2023-12-29_E1--JOB-20231231-201835.csv\n",
      "------------------------------------------\n",
      "All good. Detected with 2127 rows\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2023-12-29'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P139, SERV_DMI_P139_Monthly_Report\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from tabulate import tabulate\n",
    "user = os.getlogin()\n",
    "basefolder = 'C:/Users/'+user+'/A&D Mortgage(1)/Docs - Servicing/DMI/REPORTS/'\n",
    "cwdteams = os.path.abspath(basefolder) \n",
    "root_folder = os.listdir(cwdteams)\n",
    "\n",
    "columnsCheck = ['InvestorCode','CategoryCode','InvestorLoanNumber','LoanNumber','ShortName','AnnualInterestRate','ServiceFeeRate','DueDate','NextPaymentNumber','IntPaidTo','PrincipalBalance','PAndIConstant','PAndIConstantFlag','EscrowBalance','EscrowAdvanceBalance','SuspenseBalance','DeferredInterestBalance','RestrictedEscrowBalance','ReplacementReservesBalance','HudBalance','ARMIndicator','AsOfDate']\n",
    "\n",
    "mistakes_dupl_csv = []\n",
    "mistakes_columns = []\n",
    "missed_file = []\n",
    "files_written = []\n",
    "file_total = 0\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year_folder in root_folder:\n",
    "    if year_folder in ['REPORTS 2024']:\n",
    "        print (year_folder)\n",
    "        year_destination = os.listdir(basefolder + year_folder)   \n",
    "        for month_folder in year_destination:\n",
    "            if '.' not in month_folder and '01-2024' in month_folder:\n",
    "                #print (month_folder)\n",
    "                month_destination = os.listdir(basefolder + year_folder + '/' + month_folder)\n",
    "                counter = 0\n",
    "                for files in month_destination:\n",
    "                    if 'P139' in files and '.csv' in files and '_E1--' in files:\n",
    "                        #print(month_folder + '\\n' + files)\n",
    "                        csvpath = basefolder + year_folder + '/'+ month_folder + '/' + files\n",
    "                        print(csvpath)\n",
    "                        counter= counter+1\n",
    "                        file_total = file_total+1\n",
    "                        if counter < 2:\n",
    "                            data = pd.read_csv(csvpath)\n",
    "                            data[\"AsOfDate\"] = files[14:24]\n",
    "                            if list(data.columns) == columnsCheck:\n",
    "                                df = pd.concat([df, data], ignore_index=True)\n",
    "                                files_written.append(files[14:24])\n",
    "                            else: \n",
    "                                mistakes_columns.append(files[14:24])\n",
    "                        else:\n",
    "                            mistakes_dupl_csv.append(csvpath)\n",
    "\n",
    "print('------------------------------------------')\n",
    "if len(files_written) == file_total:\n",
    "    print(f'All good. Detected with {len(df)} rows')\n",
    "    print('------------------------------------------')\n",
    "else:\n",
    "    if len(mistakes_dupl_csv) >0:\n",
    "        print('Duplicated csvs path: '+ str(mistakes_dupl_csv))\n",
    "        print('------------------------------------------')\n",
    "    if len(mistakes_columns) >0:\n",
    "        print('Wrong Columns: '+ str(mistakes_columns))\n",
    "        print('------------------------------------------')\n",
    "np.unique(df['AsOfDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import String\n",
    "\n",
    "engine = create_engine(\"mssql+pyodbc://bi_report:kqFD45BGQ30Gc3DVXFei5PAXIe3k6pq3@bi-01.prod.admortgage.com/dm01?driver=ODBC Driver 17 for SQL Server\")\n",
    "df.to_sql('SERV_DMI_P139_Monthly_Report', con=engine, index = False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORTS 2024\n",
      "01-2024  Q05_LossMit_Report.xlsx  2023-12-29\n",
      "------------------------------------------\n",
      "All good. Added 60 rows\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# SERV_DMI_Q05_LossMit_Monthly_Report\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import openpyxl\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def excel_to_dict(excel_path, sheetname):\n",
    "    wb = openpyxl.load_workbook(excel_path)\n",
    "    sheet = wb[sheetname]\n",
    "    result_dict = []\n",
    "    headers =[]\n",
    "    for column in range(1, sheet.max_column + 1):\n",
    "        headers.append(sheet.cell(1, column).value.strip())\n",
    "    for row in range(2, sheet.max_row + 1):\n",
    "        line = dict()\n",
    "        for header in headers:\n",
    "            cell_value = sheet.cell(row, headers.index(header)+1).value\n",
    "            if type(cell_value) is str:\n",
    "                cell_value = cell_value.encode('utf-8').decode('ascii', 'ignore')\n",
    "                cell_value = cell_value.strip()\n",
    "            elif type(cell_value) is int:\n",
    "                cell_value = str(cell_value)\n",
    "            elif type(cell_value) == datetime.datetime:\n",
    "                cell_value = cell_value.strftime(\"%Y-%m-%d\")\n",
    "                #cell_value = parse(cell_value, fuzzy=False, ignoretz=True)\n",
    "            elif cell_value is None:\n",
    "                cell_value = ''\n",
    "            line[header] = cell_value\n",
    "        result_dict.append(line)\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "# from tabulate import tabulate\n",
    "user = os.getlogin()\n",
    "basefolder = 'C:/Users/'+user+'/A&D Mortgage(1)/Docs - Servicing/DMI/REPORTS/'\n",
    "cwdteams = os.path.abspath(basefolder) \n",
    "root_folder = os.listdir(cwdteams)\n",
    "\n",
    "columnsCheck = ['LOAN NUMBER',\n",
    "'INVESTOR ID',\n",
    "'INVESTOR LOAN NUMBER',\n",
    "'CATEGORY NUMBER',\n",
    "'OLD LOAN NUMBER',\n",
    "'MORTGAGOR NAME',\n",
    "'PROPERTY STREET ADDRESS',\n",
    "'CITY NAME',\n",
    "'PROPERTY ALPHA STATE CODE',\n",
    "'PROPERTY ZIP CODE',\n",
    "'Borrower Phone Number',\n",
    "'FIRST PRINCIPAL BALANCE',\n",
    "'SECOND PRINCIPAL BALANCE',\n",
    "'ESCROW BALANCE',\n",
    "'ESCROW ADVANCE BALANCE',\n",
    "'SUSPENSE BALANCE',\n",
    "'ORIGINAL MTG AMOUNT',\n",
    "'ORIGINAL PROPERTY VALUE',\n",
    "'CURRENT PROPERTY VALUE',\n",
    "'OCCUPANCY STATUS CODE',\n",
    "'LOAN  TYPE',\n",
    "'MAN CODE',\n",
    "'MAN CODE DESCRIPTION',\n",
    "'Purpose Code',\n",
    "'Servicing Sold ID (SSID)',\n",
    "'NEXT PAYMENT DUE DATE',\n",
    "'PAID IN FULL DATE',\n",
    "'NOTE DATE',\n",
    "'Original Maturity Date',\n",
    "'Current Maturity Date',\n",
    "'INTEREST RATE',\n",
    "'P+I AMOUNT',\n",
    "'T+I AMOUNT',\n",
    "'ACCRUAL STATUS',\n",
    "'LOSS MIT DENIAL REASON CODE',\n",
    "'LOSS MIT DENIAL REASON CODE DESCRIPTION',\n",
    "'LOSS MIT PROCESSOR ID',\n",
    "'LOSS MIT REMOVAL DATE',\n",
    "'LOSS MIT SET UP DATE',\n",
    "'LOSS MIT STAGE CODE',\n",
    "'LOSS MIT STAGE DESCRIPTION ',\n",
    "'LOSS MIT STATUS CODE',\n",
    "'LOSS MIT STATUS CODE DESCRIPTION',\n",
    "'LOSS MIT TEMPLATE NAME',\n",
    "'LOSS MIT TYPE CODE',\n",
    "'REFERRAL CODE',\n",
    "'GSE TYPE',\n",
    "'BANKRUPTCY STATUS',\n",
    "'FORECLOSURE STATUS',\n",
    "'NO NOTICE STOP',\n",
    "'LATE CHARGE STOP',\n",
    "'APPROVED/DENIED DATE',\n",
    "'Investor Decision Requested Date (Portfolio Loans)',\n",
    "'Investor Approval Received Date (Portfolio Loans)',\n",
    "'Client Direct Modification Received Date',\n",
    "'OPTOUT Task Open Date',\n",
    "'OPTOUT Task Closed Date',\n",
    "'Systems automated: Borrower is current - no QRPC - Remove FB',\n",
    "'Forbearance Start Date',\n",
    "'Initial Forbearance Agreement Letter Sent to Borrower',\n",
    "'#1 Forbearance Payment Plan Amount',\n",
    "'#1 Forbearance Payment Plan Date',\n",
    "'#2 Forbearance Payment Plan Amount',\n",
    "'#2 Forbearance Payment Plan Date',\n",
    "'#3 Forbearance Payment Plan Amount',\n",
    "'#3 Forbearance Payment Plan Date',\n",
    "'Initial Forbearance End Date',\n",
    "'Forbearance Extension #1 Start Date',\n",
    "'Forbearance Extension #1 Letter Sent',\n",
    "'#4 Forbearance Payment Plan Amount',\n",
    "'#4 Forbearance Payment Plan Date',\n",
    "'#5 Forbearance Payment Plan Amount',\n",
    "'#5 Forbearance Payment Plan Date',\n",
    "'#6 Forbearance Payment Plan Amount',\n",
    "'#6 Forbearance Payment Plan Date',\n",
    "'Forbearance Extension #1 End Date',\n",
    "'Forbearance Extension #2 Start Date',\n",
    "'Forbearance Extension #2 Letter Sent',\n",
    "'#7 Forbearance Payment Plan Amount',\n",
    "'#7 Forbearance Payment Plan Date',\n",
    "'#8 Forbearance Payment Plan Amount',\n",
    "'#8 Forbearance Payment Plan Date',\n",
    "'#9 Forbearance Payment Plan Amount',\n",
    "'#9 Forbearance Payment Plan Date',\n",
    "'Forbearance Extension #2 End Date',\n",
    "'Forbearance Extension #3 Start Date',\n",
    "'Forbearance Extension #3 Letter Sent',\n",
    "'#10 Forbearance Payment Plan Amount',\n",
    "'#10 Forbearance Payment Plan Date',\n",
    "'#11 Forbearance Payment Plan Amount',\n",
    "'#11 Forbearance Payment Plan Date',\n",
    "'#12 Forbearance Payment Plan Amount',\n",
    "'#12 Forbearance Payment Plan Date',\n",
    "'Forbearance Extension #3 End Date',\n",
    "'Forbearance Extension Request #4 Start Date',\n",
    "'Forbearance Extension #4 Letter Sent',\n",
    "'#13 Forbearance Payment Plan Amount',\n",
    "'#13 Forbearance Payment Plan Date',\n",
    "'#14 Forbearance Payment Plan Amount',\n",
    "'#14 Forbearance Payment Plan Date',\n",
    "'#15 Forbearance Payment Plan Amount',\n",
    "'#15 Forbearance Payment Plan Date',\n",
    "'Forbearance Extension #4 End Date',\n",
    "'Forbearance Extension Request #5 Start Date',\n",
    "'Forbearance Extension #5 Letter Sent',\n",
    "'#16 Forbearance Payment Plan Amount',\n",
    "'#16 Forbearance Payment Plan Date',\n",
    "'#17 Forbearance Payment Plan Amount',\n",
    "'#17 Forbearance Payment Plan Date',\n",
    "'#18 Forbearance Payment Plan Amount',\n",
    "'#18 Forbearance Payment Plan Date',\n",
    "'Forbearance Extension #5 End Date',\n",
    "'Forbearance Extension Request #6 Start Date',\n",
    "'Forbearance Extension #6 Letter Sent',\n",
    "'#19 Forbearance Payment Plan Amount',\n",
    "'#19 Forbearance Payment Plan Date',\n",
    "'#20 Forbearance Payment Plan Amount',\n",
    "'#20 Forbearance Payment Plan Date',\n",
    "'#21 Forbearance Payment Plan Amount',\n",
    "'#21 Forbearance Payment Plan Date',\n",
    "'Forbearance Extension #6 End Date',\n",
    "'Total Number of Months Approved for Forbearance ',\n",
    "'Deferment Processed (Y/N)',\n",
    "'Total Deferment Months Granted',\n",
    "'Extension Request Acknowledgement Email Sent Date',\n",
    "'Extension Solicitation Email Sent Date',\n",
    "'Extension Solicitation Phone Call Date',\n",
    "'Extension Solicitation Phone Call No-QRPC',\n",
    "'Extension Solicitation Mail Date',\n",
    "'Loss Mit SPOC Extension Request',\n",
    "'Loss Mit SPOC 2nd Step/Post-FB Request',\n",
    "'Loss Mit SPOC Opt-Out',\n",
    "'BITB Extension Request ',\n",
    "'BITB 2nd Step/Post-FB Request',\n",
    "'IVR Extension Request ',\n",
    "'IVR 2nd Step/Post-FB Request',\n",
    "'IVR Opt-Out Request',\n",
    "'Hardship Reason ',\n",
    "'Partial Claim Accepted by Borrower',\n",
    "'Deferment Option Accepted by Borrower',\n",
    "'Deferment Letter Sent Date',\n",
    "'Deferred Amount',\n",
    "'MOD Effective Date',\n",
    "'CBR INDICATOR ',\n",
    "'CBR EXPIR',\n",
    "'CBR STATUS',\n",
    "'CBR STATUS DESCRIPTION',\n",
    "'CBR COMMENT CODE',\n",
    "'CBR DEFAULT PAYMENT PLAN INDICATOR',\n",
    "'Systems automated: Borrower is delinquent-no QRPC- Automatic FB Extension',\n",
    "'Source',\n",
    "'Action',\n",
    "'Due Date as of March 2020',\n",
    "'AsOfDate'\n",
    "]\n",
    "\n",
    "mistakes_dupl_csv = []\n",
    "mistakes_columns = []\n",
    "missed_file = []\n",
    "files_written = []\n",
    "file_total = 0\n",
    "counter = 0\n",
    "data_corrected = []\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year_folder in root_folder:\n",
    "    if 'REPORTS 2024' in year_folder:\n",
    "        print (year_folder)\n",
    "        year_destination = os.listdir(basefolder + year_folder)   \n",
    "        for month_folder in year_destination:\n",
    "            if '.' not in month_folder and '01-2024' in month_folder:\n",
    "                #print (month_folder)\n",
    "                month_destination = os.listdir(basefolder + year_folder + '/' + month_folder)\n",
    "                counter = 0\n",
    "                for files in month_destination:\n",
    "                    if 'P185' in files and '_D--' in files and '.csv' in files:\n",
    "                        datetowrite = files[14:24]\n",
    "                    if 'Q05_LossMit_Report.xlsx' in files:\n",
    "                        print(month_folder + '  ' + files + '  ' + datetowrite)\n",
    "                        csvpath = basefolder + year_folder + '/'+ month_folder + '/' + files\n",
    "                        counter= counter+1\n",
    "                        file_total = file_total+1\n",
    "                        if counter < 2:\n",
    "                            data_dict = excel_to_dict(csvpath, 'Details')\n",
    "                            data = pd.read_excel(csvpath, 'Details')\n",
    "                            data[\"AsOfDate\"] = datetowrite\n",
    "                            #data_dict = data.to_dict('records')\n",
    "                            status = ''\n",
    "                            for i in range(len(data_dict)):\n",
    "                                if data_dict[i]['INVESTOR ID'] == '':\n",
    "                                    status = data_dict[i]['LOAN NUMBER']\n",
    "                                else:\n",
    "                                    data_dict[i]['LOAN STATUS'] = status\n",
    "                                    data_dict[i]['AsOfDate'] = datetowrite\n",
    "                                    data_corrected.append(data_dict[i])\n",
    "                            if list(data.columns) == columnsCheck:\n",
    "                                files_written.append(datetowrite)\n",
    "                            else: \n",
    "                                mistakes_columns.append(datetowrite)\n",
    "                        else:\n",
    "                            mistakes_dupl_csv.append(csvpath)\n",
    "\n",
    "print('------------------------------------------')\n",
    "if len(files_written) == file_total:\n",
    "    print(f'All good. Added {len(data_corrected)} rows')\n",
    "    print('------------------------------------------')\n",
    "else:\n",
    "    if len(mistakes_dupl_csv) >0:\n",
    "        print('Duplicated csvs path: '+ mistakes_dupl_csv)\n",
    "        print('------------------------------------------')\n",
    "    if len(mistakes_columns) >0:\n",
    "        print('Wrong columns: '+ str(mistakes_columns))\n",
    "        print('------------------------------------------')\n",
    "df = pd.DataFrame(data_corrected) \n",
    "df.to_csv(\"DMI_LossMit.csv\", index=False)\n",
    "np.unique(df['AsOfDate'])\n",
    "\n",
    "import pyodbc\n",
    "def listNestedDictForTblInsert(data):\n",
    "    '''Convert the list of dictionaries into list of tuples'''   \n",
    "    tuples_list = []\n",
    "    for i in range(len(data)):\n",
    "        values_tuple = []\n",
    "        for value in (data[i].values()):\n",
    "            if value == '':\n",
    "                values_tuple.append(None)\n",
    "            elif value == True:\n",
    "                values_tuple.append(1)\n",
    "            elif value == False:\n",
    "                values_tuple.append(0)\n",
    "            else:\n",
    "                values_tuple.append(value)\n",
    "        values_tuple = tuple(values_tuple)   \n",
    "        tuples_list.append(values_tuple)\n",
    "    return tuples_list\n",
    "\n",
    "def insert_sql(table, data, server, database, username, password):\n",
    "    values = listNestedDictForTblInsert(data)\n",
    "    columns = ', '.join('' + str(x).replace('/', '_').replace(' ', '_').replace(':', '').replace('-', '_').replace('(','').replace(')','').replace('+', '_').replace('#','_').replace('___','_').replace('__','_') + '' for x in data[0].keys())\n",
    "    questions = ', '.join(\"?\" for x in data[0].keys())\n",
    "    query = \"INSERT INTO %s ( %s ) \\nVALUES ( %s );\" % (table, columns, questions)\n",
    "    conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server}; Server='+server+';UID='+username+'; PWD='+password+'; DataBase='+database)\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.fast_executemany = True\n",
    "        cursor.executemany(query, values)\n",
    "        conn.commit()\n",
    "        #messagebox.showinfo(\"show info\", table+\":\\nData is saved successfully\")\n",
    "        print(table,\" - all good!\")\n",
    "    except pyodbc.Error as e:\n",
    "        #messagebox.showinfo(\"show info\", \"Data is not saved!\\n\"+str(e))\n",
    "        print(table,': ',e)\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERV_DMI_Q05_LossMit_Monthly_Report  - all good!\n"
     ]
    }
   ],
   "source": [
    "# Server parameters\n",
    "server = 'bi-01.prod.admortgage.com'\n",
    "database = 'dm01'\n",
    "username = 'bi_report'\n",
    "password = 'kqFD45BGQ30Gc3DVXFei5PAXIe3k6pq3'\n",
    "\n",
    "insert_sql('SERV_DMI_Q05_LossMit_Monthly_Report', data_corrected, server, database, username, password)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
